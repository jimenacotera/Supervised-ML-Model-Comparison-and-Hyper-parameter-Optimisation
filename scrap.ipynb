{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, TargetEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import plotly\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model,num,cat):\n",
    "    start_time = time.time()\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"Now fitting\", model, cat, num)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    # Hyperparameter fields \n",
    "    train_pct = 0.8\n",
    "    MIN_FREQ_CAT = 1000  \n",
    "    MAX_CAT = 10\n",
    "\n",
    "    # 1. INPUT PARSING -------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Read input files \n",
    "    # Check the files exist and can be read\n",
    "    def check_and_read_csv(filepath):\n",
    "        # Check if file exists at specified location\n",
    "        if not os.path.exists(filepath):\n",
    "            print(\"Error: the file '\" + filepath + \"' does not exist\", file= sys.stderr)\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Check if file is empty\n",
    "        if os.path.getsize(filepath) == 0:\n",
    "            print(f\"Error: The file '{filepath}' is empty.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        try:\n",
    "            # Read the file into a DataFrame\n",
    "            df = pd.read_csv(filepath)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file '{filepath}': {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    train_input_file = \"./Pump_it_Up_Data_Mining_the_Water_Table_-_Training_set_values.csv\"\n",
    "    train_labels_file = \"./Pump_it_Up_Data_Mining_the_Water_Table_-_Training_set_labels.csv\"\n",
    "    test_input_file = \"./Pump_it_Up_Data_Mining_the_Water_Table_-_Test_set_values.csv\"\n",
    "\n",
    "\n",
    "    # Import data from specificed locations\n",
    "    train_values = check_and_read_csv(train_input_file)\n",
    "    train_labels = check_and_read_csv(train_labels_file)\n",
    "    test_values = check_and_read_csv(test_input_file)\n",
    "\n",
    "    # User Input Fields\n",
    "    numerical_preprocessing = num\n",
    "    categorical_preprocessing = cat\n",
    "    model_type = model\n",
    "    test_output_file = \"predicted-values.csv\"\n",
    "\n",
    "\n",
    "    # Confirming that training values and labels match, \n",
    "    n_train_samples = len(train_values.index) \n",
    "    n_train_labels = len(train_labels.index)\n",
    "    if n_train_samples != n_train_labels: \n",
    "        print(\"Error: number of training samples and labels not equal.\")\n",
    "        sys.exit(1)\n",
    "    # Check features exist\n",
    "    if len(train_values.columns) <= 1:\n",
    "        print(\"Error: not enough features in training data.\")\n",
    "        sys.exit(1)\n",
    "    elif len(test_values.columns) <= 1: \n",
    "        print(\"Error: not enough features in testing data.\")\n",
    "        sys.exit(1)\n",
    "    # Confirm training and testing features are the same\n",
    "    if set(train_values.columns) != set(test_values.columns): \n",
    "        print(\"Error: training and testing features do not match.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 2. Data Preprocessing ----------------------------------------------------\n",
    "\n",
    "    # Converting 'date_recorded' into a numerical feature: \n",
    "    #train_values[\"date_recorded\"] = pd.to_datetime(train_values.date_recorded, format=\"%Y-%m-%d\") \n",
    "\n",
    "    # Creating transformer for datetime \n",
    "    def transform_date_sin_cos(df): \n",
    "        df[\"date_recorded\"] = pd.to_datetime(df.date_recorded, format=\"%Y-%m-%d\") \n",
    "        df[\"day\"] = df[\"date_recorded\"].dt.day\n",
    "        df[\"month\"] = df[\"date_recorded\"].dt.month\n",
    "        df[\"year\"] = df[\"date_recorded\"].dt.year \n",
    "\n",
    "        df[\"day_sin\"] = np.sin(2 * np.pi * df[\"day\"] / 31)\n",
    "        df[\"day_cos\"] = np.cos(2 * np.pi * df[\"day\"] / 31)\n",
    "\n",
    "        df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "        df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "\n",
    "        df[\"year_sin\"] = np.sin(2 * np.pi * (df[\"year\"] % 10) / 3)  \n",
    "        df[\"year_cos\"] = np.cos(2 * np.pi * (df[\"year\"] % 10) / 3)\n",
    "\n",
    "        df.drop(columns=[\"day\", \"month\", \"year\", \"date_recorded\"], inplace=True)\n",
    "        return df\n",
    "\n",
    "    date_transformer = FunctionTransformer(transform_date_sin_cos, validate=False)\n",
    "\n",
    "\n",
    "\n",
    "    numeric_cols = train_values.select_dtypes(include=[\"int64\", \"float64\"], exclude=[\"object\", \"datetime\"]).drop(columns=[\"id\"]).columns\n",
    "    categoric_cols = train_values.select_dtypes(include=[\"object\"], exclude=[\"int64\", \"float64\", \"datetime\"]).columns\n",
    "    #datetime_cols = train_values.select_dtypes(include=[\"datetime\"], exclude=[\"int64\", \"float64\", \"object\"]).columns\n",
    "\n",
    "\n",
    "    if categorical_preprocessing == \"OneHotEncoder\":\n",
    "        encoder = OneHotEncoder(\n",
    "            min_frequency= MIN_FREQ_CAT\n",
    "            #   , max_categories = MAX_CAT\n",
    "            , \n",
    "            handle_unknown='infrequent_if_exist'\n",
    "            #   , drop= \"first\"\n",
    "        , sparse_output= False # Linear regression performs poorly on sparse data\n",
    "        )   \n",
    "    elif categorical_preprocessing == \"OrdinalEncoder\":\n",
    "        encoder = OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\"\n",
    "            , unknown_value=-1\n",
    "            , encoded_missing_value= -1 #TODO esto esta bien???\n",
    "            #   , dtype=float\n",
    "              , min_frequency = MIN_FREQ_CAT\n",
    "            # , max_categories = MAX_CAT\n",
    "        )\n",
    "    elif categorical_preprocessing == \"TargetEncoder\":\n",
    "        encoder = TargetEncoder(\n",
    "            target_type = \"multiclass\"\n",
    "        )\n",
    "\n",
    "\n",
    "    # Numerical preprocessing\n",
    "    if numerical_preprocessing == \"StandardScaler\" :\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = \"passthrough\"\n",
    "\n",
    "    \n",
    "\n",
    "    # Transformer object with scaler and encoder\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "            ('date', date_transformer,[\"date_recorded\"] ),\n",
    "            ('num', scaler, numeric_cols),\n",
    "            ('cat', encoder, categoric_cols)],\n",
    "    verbose=False)\n",
    "\n",
    "\n",
    "    # Split the data into train and test sets \n",
    "    train_values.drop(columns=[\"id\"], inplace = True)\n",
    "    train_labels.drop(columns=[\"id\"], inplace = True)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_values, train_labels, train_size = train_pct)\n",
    "\n",
    "    # Apply to the training data \n",
    "    if categorical_preprocessing == \"TargetEncoder\": \n",
    "        X_train_transformed = preprocessor.fit_transform(X_train, y_train[\"status_group\"])\n",
    "    else: \n",
    "        X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "\n",
    "    # 3. Model Training and Evaluation -------------------------------------------------------\n",
    "\n",
    "\n",
    "    if model_type == \"LogisticRegression\": \n",
    "        model = LogisticRegression()\n",
    "    elif model_type == \"RandomForestClassifier\": \n",
    "        model = RandomForestClassifier()\n",
    "    elif model_type == \"GradientBoostingClassifier\": \n",
    "        model = GradientBoostingClassifier( )\n",
    "    elif model_type == \"HistGradientBoostingClassifier\":\n",
    "        model = HistGradientBoostingClassifier()\n",
    "    elif model_type == \"MLPClassifier\":\n",
    "        model = MLPClassifier()\n",
    "\n",
    "\n",
    "    model.fit(X_train_transformed, y_train.values.ravel())\n",
    "\n",
    "    # Cross Validation on the training set\n",
    "    folds = KFold(n_splits=5, random_state=100, shuffle=True)\n",
    "    cv = cross_val_score(estimator=model,\n",
    "                        X=X_train_transformed,\n",
    "                        y=y_train.values.ravel(),\n",
    "                        cv=folds,\n",
    "                        scoring='accuracy')\n",
    "    \n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(model, cat, num)\n",
    "    print(\"The cross validation accuracy \")\n",
    "    print(cv)\n",
    "    print(\"Mean of the cross validation scores is: \", cv.mean())\n",
    "    print(\"Standard dev of the cross validation scores is: \", cv.std())\n",
    "\n",
    "\n",
    "    # calculate classification accuracy of the trained model on the validation set\n",
    "    X_val_preprocessed = preprocessor.transform(X_val) # first we need to preprocess the input\n",
    "    y_val_pred = model.predict(X_val_preprocessed) # then make the predictions\n",
    "    acc_val = accuracy_score(y_pred=y_val_pred, y_true=y_val) # calculate the score\n",
    "    print(f\"classification accuracy on the validation set: {acc_val:.4f}\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "\n",
    "    # 4. Prediction Generation -------------------------------------------------\n",
    "    # Preprocessing\n",
    "    # Outlier Handling in Numeric Fields through imputation\n",
    "    # Remove row where construction year is 0 -> missing data\n",
    "    # mask = test_values['construction_year'] != 0\n",
    "    # test_values = test_values[mask].reset_index(drop=True)\n",
    "\n",
    "    # # Removing amount_tsh column from training data due to high # of NaNs\n",
    "    # test_values.drop(columns=[\"amount_tsh\"])\n",
    "\n",
    "    # Transform test data with same encoder\n",
    "    X_test = preprocessor.transform(test_values)\n",
    "\n",
    "    # Make prediction\n",
    "    y_test = model.predict(X_test)\n",
    "    output_test = pd.DataFrame({\"id\": test_values[\"id\"].values, \"status_group\": y_test})\n",
    "\n",
    "    # Write prediction to file \n",
    "    output_test.to_csv(test_output_file, index=False)\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    minutes, seconds = divmod(execution_time, 60)\n",
    "\n",
    "    print(f\"Execution Time: {int(minutes)} minutes and {seconds:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting LogisticRegression TargetEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LogisticRegression() TargetEncoder None\n",
      "The cross validation accuracy \n",
      "[0.54713805 0.56060606 0.5535564  0.55218855 0.5547138 ]\n",
      "Mean of the cross validation scores is:  0.5536405723905723\n",
      "Standard dev of the cross validation scores is:  0.004337467843600323\n",
      "classification accuracy on the validation set: 0.5559\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 2 minutes and 6.49 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting LogisticRegression OneHotEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LogisticRegression() OneHotEncoder None\n",
      "The cross validation accuracy \n",
      "[0.58322811 0.56365741 0.55702862 0.56155303 0.59553872]\n",
      "Mean of the cross validation scores is:  0.5722011784511785\n",
      "Standard dev of the cross validation scores is:  0.014716112365171423\n",
      "classification accuracy on the validation set: 0.5604\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 2 minutes and 56.50 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting LogisticRegression OrdinalEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LogisticRegression() OrdinalEncoder None\n",
      "The cross validation accuracy \n",
      "[0.597117   0.57828283 0.58364899 0.58007155 0.58301768]\n",
      "Mean of the cross validation scores is:  0.5844276094276095\n",
      "Standard dev of the cross validation scores is:  0.006638500980582138\n",
      "classification accuracy on the validation set: 0.5684\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 48.61 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting LogisticRegression TargetEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LogisticRegression() TargetEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.75873316 0.7706229  0.7645202  0.7572601  0.7662037 ]\n",
      "Mean of the cross validation scores is:  0.7634680134680134\n",
      "Standard dev of the cross validation scores is:  0.0049140697537750876\n",
      "classification accuracy on the validation set: 0.7655\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 2 minutes and 9.94 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting LogisticRegression OneHotEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LogisticRegression() OneHotEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.73148148 0.73611111 0.73779461 0.73537458 0.74484428]\n",
      "Mean of the cross validation scores is:  0.7371212121212121\n",
      "Standard dev of the cross validation scores is:  0.004381250464495836\n",
      "classification accuracy on the validation set: 0.7363\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 2 minutes and 56.16 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting LogisticRegression OrdinalEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LogisticRegression() OrdinalEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.63015572 0.64541246 0.64099327 0.64930556 0.63846801]\n",
      "Mean of the cross validation scores is:  0.6408670033670034\n",
      "Standard dev of the cross validation scores is:  0.0065172528345551475\n",
      "classification accuracy on the validation set: 0.6440\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 50.70 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting RandomForestClassifier TargetEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RandomForestClassifier() TargetEncoder None\n",
      "The cross validation accuracy \n",
      "[0.78356481 0.79934764 0.79619108 0.79029882 0.80071549]\n",
      "Mean of the cross validation scores is:  0.7940235690235691\n",
      "Standard dev of the cross validation scores is:  0.006341686263244906\n",
      "classification accuracy on the validation set: 0.8090\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 1 minutes and 6.62 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting RandomForestClassifier OneHotEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RandomForestClassifier() OneHotEncoder None\n",
      "The cross validation accuracy \n",
      "[0.80039983 0.80113636 0.7962963  0.80313552 0.80039983]\n",
      "Mean of the cross validation scores is:  0.8002735690235688\n",
      "Standard dev of the cross validation scores is:  0.0022264667784000903\n",
      "classification accuracy on the validation set: 0.8082\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 25.30 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting RandomForestClassifier OrdinalEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RandomForestClassifier() OrdinalEncoder None\n",
      "The cross validation accuracy \n",
      "[0.80103114 0.80650253 0.80744949 0.81007997 0.80145202]\n",
      "Mean of the cross validation scores is:  0.8053030303030303\n",
      "Standard dev of the cross validation scores is:  0.0035197869574166846\n",
      "classification accuracy on the validation set: 0.8003\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 24.24 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting RandomForestClassifier TargetEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RandomForestClassifier() TargetEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.79513889 0.79850589 0.79377104 0.79461279 0.79503367]\n",
      "Mean of the cross validation scores is:  0.7954124579124578\n",
      "Standard dev of the cross validation scores is:  0.0016199603749089124\n",
      "classification accuracy on the validation set: 0.8019\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 1 minutes and 6.78 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting RandomForestClassifier OneHotEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RandomForestClassifier() OneHotEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.79787458 0.79955808 0.7996633  0.79640152 0.8013468 ]\n",
      "Mean of the cross validation scores is:  0.7989688552188553\n",
      "Standard dev of the cross validation scores is:  0.0016895409353256772\n",
      "classification accuracy on the validation set: 0.8109\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 25.14 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting RandomForestClassifier OrdinalEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "RandomForestClassifier() OrdinalEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.8018729  0.80166246 0.80281987 0.80387205 0.79461279]\n",
      "Mean of the cross validation scores is:  0.8009680134680135\n",
      "Standard dev of the cross validation scores is:  0.003272695447116295\n",
      "classification accuracy on the validation set: 0.8050\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 24.25 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting GradientBoostingClassifier TargetEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "GradientBoostingClassifier() TargetEncoder None\n",
      "The cross validation accuracy \n",
      "[0.77977694 0.78093434 0.78798401 0.77104377 0.79440236]\n",
      "Mean of the cross validation scores is:  0.7828282828282829\n",
      "Standard dev of the cross validation scores is:  0.007903329948743232\n",
      "classification accuracy on the validation set: 0.7792\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 7 minutes and 42.61 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting GradientBoostingClassifier OneHotEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "GradientBoostingClassifier() OneHotEncoder None\n",
      "The cross validation accuracy \n",
      "[0.76325758 0.7611532  0.75094697 0.75652357 0.74726431]\n",
      "Mean of the cross validation scores is:  0.7558291245791245\n",
      "Standard dev of the cross validation scores is:  0.006019989931033105\n",
      "classification accuracy on the validation set: 0.7575\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 3 minutes and 25.94 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting GradientBoostingClassifier OrdinalEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "GradientBoostingClassifier() OrdinalEncoder None\n",
      "The cross validation accuracy \n",
      "[0.75031566 0.74852694 0.75178872 0.74873737 0.74905303]\n",
      "Mean of the cross validation scores is:  0.7496843434343434\n",
      "Standard dev of the cross validation scores is:  0.001221626706540438\n",
      "classification accuracy on the validation set: 0.7374\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 2 minutes and 11.98 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting GradientBoostingClassifier TargetEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "GradientBoostingClassifier() TargetEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.78714226 0.77872475 0.7773569  0.78440657 0.78209175]\n",
      "Mean of the cross validation scores is:  0.7819444444444444\n",
      "Standard dev of the cross validation scores is:  0.003592018231203993\n",
      "classification accuracy on the validation set: 0.7785\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 7 minutes and 45.75 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting GradientBoostingClassifier OneHotEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "GradientBoostingClassifier() OneHotEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.75999579 0.7522096  0.75704966 0.75810185 0.753367  ]\n",
      "Mean of the cross validation scores is:  0.7561447811447811\n",
      "Standard dev of the cross validation scores is:  0.0029216758235368046\n",
      "classification accuracy on the validation set: 0.7588\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 3 minutes and 27.88 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting GradientBoostingClassifier OrdinalEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "GradientBoostingClassifier() OrdinalEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.74463384 0.74884259 0.74358165 0.74894781 0.75094697]\n",
      "Mean of the cross validation scores is:  0.7473905723905723\n",
      "Standard dev of the cross validation scores is:  0.002803169327499444\n",
      "classification accuracy on the validation set: 0.7424\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 2 minutes and 10.59 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting HistGradientBoostingClassifier TargetEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "HistGradientBoostingClassifier() TargetEncoder None\n",
      "The cross validation accuracy \n",
      "[0.79692761 0.79776936 0.79156145 0.79650673 0.7907197 ]\n",
      "Mean of the cross validation scores is:  0.7946969696969697\n",
      "Standard dev of the cross validation scores is:  0.002944173233212129\n",
      "classification accuracy on the validation set: 0.8069\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 40.31 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting HistGradientBoostingClassifier OneHotEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "HistGradientBoostingClassifier() OneHotEncoder None\n",
      "The cross validation accuracy \n",
      "[0.7974537  0.7940867  0.78977273 0.78398569 0.79114057]\n",
      "Mean of the cross validation scores is:  0.7912878787878788\n",
      "Standard dev of the cross validation scores is:  0.004505333281679012\n",
      "classification accuracy on the validation set: 0.7990\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 48.94 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting HistGradientBoostingClassifier OrdinalEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "HistGradientBoostingClassifier() OrdinalEncoder None\n",
      "The cross validation accuracy \n",
      "[0.78777357 0.78777357 0.79545455 0.79545455 0.79703283]\n",
      "Mean of the cross validation scores is:  0.7926978114478114\n",
      "Standard dev of the cross validation scores is:  0.00406172039000877\n",
      "classification accuracy on the validation set: 0.7872\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 38.79 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting HistGradientBoostingClassifier TargetEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "HistGradientBoostingClassifier() TargetEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.79482323 0.8013468  0.80071549 0.79840067 0.7901936 ]\n",
      "Mean of the cross validation scores is:  0.7970959595959597\n",
      "Standard dev of the cross validation scores is:  0.0041395830996420096\n",
      "classification accuracy on the validation set: 0.8002\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 41.31 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting HistGradientBoostingClassifier OneHotEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "HistGradientBoostingClassifier() OneHotEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.7957702  0.78693182 0.78808923 0.79871633 0.78703704]\n",
      "Mean of the cross validation scores is:  0.7913089225589226\n",
      "Standard dev of the cross validation scores is:  0.0049507008826586395\n",
      "classification accuracy on the validation set: 0.7950\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 48.25 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting HistGradientBoostingClassifier OrdinalEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "HistGradientBoostingClassifier() OrdinalEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.79471801 0.78777357 0.79345539 0.79450758 0.78619529]\n",
      "Mean of the cross validation scores is:  0.7913299663299663\n",
      "Standard dev of the cross validation scores is:  0.0036085005436653603\n",
      "classification accuracy on the validation set: 0.7842\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 36.80 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting MLPClassifier TargetEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MLPClassifier() TargetEncoder None\n",
      "The cross validation accuracy \n",
      "[0.76241582 0.60279882 0.74358165 0.72253788 0.72874579]\n",
      "Mean of the cross validation scores is:  0.7120159932659933\n",
      "Standard dev of the cross validation scores is:  0.05631255724619693\n",
      "classification accuracy on the validation set: 0.7546\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 38.68 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting MLPClassifier OneHotEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MLPClassifier() OneHotEncoder None\n",
      "The cross validation accuracy \n",
      "[0.7315867  0.71012205 0.69707492 0.7276936  0.69444444]\n",
      "Mean of the cross validation scores is:  0.7121843434343436\n",
      "Standard dev of the cross validation scores is:  0.015259360623777384\n",
      "classification accuracy on the validation set: 0.7322\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 56.24 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting MLPClassifier OrdinalEncoder None\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MLPClassifier() OrdinalEncoder None\n",
      "The cross validation accuracy \n",
      "[0.5993266  0.50989057 0.6412037  0.65603956 0.68129209]\n",
      "Mean of the cross validation scores is:  0.617550505050505\n",
      "Standard dev of the cross validation scores is:  0.06004438776835912\n",
      "classification accuracy on the validation set: 0.6611\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 0 minutes and 15.52 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting MLPClassifier TargetEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MLPClassifier() TargetEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.78356481 0.7829335  0.77714646 0.78009259 0.78261785]\n",
      "Mean of the cross validation scores is:  0.7812710437710437\n",
      "Standard dev of the cross validation scores is:  0.002376549007051586\n",
      "classification accuracy on the validation set: 0.7767\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 2 minutes and 31.11 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting MLPClassifier OneHotEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MLPClassifier() OneHotEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.76694024 0.76820286 0.77272727 0.77977694 0.77209596]\n",
      "Mean of the cross validation scores is:  0.7719486531986531\n",
      "Standard dev of the cross validation scores is:  0.004495000724811765\n",
      "classification accuracy on the validation set: 0.7735\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 3 minutes and 4.97 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Now fitting MLPClassifier OrdinalEncoder StandardScaler\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MLPClassifier() OrdinalEncoder StandardScaler\n",
      "The cross validation accuracy \n",
      "[0.75883838 0.77451599 0.7684133  0.76073232 0.76578283]\n",
      "Mean of the cross validation scores is:  0.7656565656565657\n",
      "Standard dev of the cross validation scores is:  0.005600727612727777\n",
      "classification accuracy on the validation set: 0.7088\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Execution Time: 1 minutes and 8.82 seconds\n"
     ]
    }
   ],
   "source": [
    "supported_models = [\"LogisticRegression\", \n",
    "                    \"RandomForestClassifier\", \n",
    "                    \"GradientBoostingClassifier\", \n",
    "                    \"HistGradientBoostingClassifier\",\n",
    "                    \"MLPClassifier\"]\n",
    "supported_numerical = [\"None\", \"StandardScaler\"]\n",
    "supported_categorical = [\"TargetEncoder\", \"OneHotEncoder\", \"OrdinalEncoder\"]\n",
    "\n",
    "for model in supported_models: \n",
    "    for num in supported_numerical: \n",
    "        for cat in supported_categorical: \n",
    "            main(model,num,cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
